{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "shared-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.stats import wasserstein_distance\n",
    "import pymysql\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varied-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.read_csv('../data/final_feature_importances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stock-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573113"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_probability = {}\n",
    "for visit_id, prob in np.array(pd.read_csv('../data/rfr_model_depth_69_trees_190_preds.csv', header=None)):\n",
    "    visit_probability[int(visit_id)] = prob\n",
    "    \n",
    "len(visit_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "literary-judgment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_variables = pickle.load(open('../data/demographic_variables.p', 'rb'))\n",
    "datetime_variables = pickle.load(open('../data/datetime_variables.p', 'rb'))\n",
    "diag_variables = pickle.load(open('../data/diag_variables.p', 'rb'))\n",
    "all_variables = demograhic_variables + datetime_variables[:-1] + diag_variables\n",
    "len(all_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "floral-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_demog = pd.read_csv('../data/all_visit_demographic_matrix.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "statewide-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variable_cases = defaultdict(list)\n",
    "\n",
    "for i in range(1,12):\n",
    "    var = demographic_variables[i-1]\n",
    "    all_variable_cases[var] = list(all_demog[0][all_demog[i]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "approximate-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datetime = pd.read_csv('../data/all_visit_date_matrix.csv', header=None)\n",
    "\n",
    "for i in range(1,len(datetime_variables)-1):\n",
    "    var = str(datetime_variables[i-1])\n",
    "    all_variable_cases[var] = list(all_datetime[0][all_datetime[i]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "focal-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tunnel first: ssh -f [uni]@mimir.dbmi.columbia.edu -L 3307:127.0.0.1:3306 -N\n",
    "\n",
    "conn = pymysql.connect(host=\"127.0.0.1\", \n",
    "                       user=\"\", #uni\n",
    "                       port = ,\n",
    "                       passwd=\"\", #sql password\n",
    "                       db = \"user_vr2430\" ) #database\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acute-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''select distinct substring_index(icd10, '.', 1), visit_id\n",
    "                from vfinal_1_predict_covid_conditions\n",
    "                where substring_index(icd10, '.', 1) != '';''')\n",
    "\n",
    "for icd10, visit_id in cur.fetchall():\n",
    "    all_variable_cases[icd10].append(visit_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "embedded-davis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1636/1636 [58:22<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "wasserstein_distance_results = {}\n",
    "\n",
    "for i in tqdm(all_variable_cases):\n",
    "    cases_prob = [visit_probability[k] for k in set(all_variable_cases[i])&set(visit_probability.keys())]\n",
    "    non_cases = list(set(visit_probability.keys())-set(all_variable_cases[i]))\n",
    "    non_cases_prob = [visit_probability[k] for k in non_cases]\n",
    "    if mean(cases_prob) > mean(non_cases_prob):\n",
    "        wasserstein_distance_results[i]= wasserstein_distance(cases_prob, non_cases_prob)\n",
    "    else:\n",
    "        wasserstein_distance_results[i]= -1*wasserstein_distance(cases_prob, non_cases_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "applied-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_training_set = pickle.load(open('../data/negative_training_set.p', 'rb'))\n",
    "positive_training_set = pickle.load(open('../data/positive_training_set.p', 'rb'))\n",
    "negative_eval_set = pickle.load(open('../data/negative_eval_set.p', 'rb'))\n",
    "positive_eval_set = pickle.load(open('../data/positive_eval_set.p', 'rb'))\n",
    "\n",
    "training_set = negative_training_set + positive_training_set\n",
    "eval_set = negative_eval_set + positive_eval_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sophisticated-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1636/1636 [02:56<00:00,  9.29it/s]\n"
     ]
    }
   ],
   "source": [
    "wasserstein_distance_results_training = {}\n",
    "\n",
    "for i in tqdm(all_variable_cases):\n",
    "    cases_prob = [visit_probability[k] for k in set(all_variable_cases[i])&set(training_set)]\n",
    "    non_cases = list((set(visit_probability.keys())-set(all_variable_cases[i]))&set(training_set))\n",
    "    non_cases_prob = [visit_probability[k] for k in non_cases]\n",
    "    if len(cases_prob) == 0 or len(non_cases_prob) == 0:\n",
    "        continue\n",
    "    if mean(cases_prob) > mean(non_cases_prob):\n",
    "        wasserstein_distance_results_training[i]= wasserstein_distance(cases_prob, non_cases_prob)\n",
    "    else:\n",
    "        wasserstein_distance_results_training[i]= -1*wasserstein_distance(cases_prob, non_cases_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "removed-lithuania",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1636/1636 [02:56<00:00,  9.26it/s]\n"
     ]
    }
   ],
   "source": [
    "wasserstein_distance_results_eval = {}\n",
    "\n",
    "for i in tqdm(all_variable_cases):\n",
    "    cases_prob = [visit_probability[k] for k in set(all_variable_cases[i])&set(eval_set)]\n",
    "    non_cases = list((set(visit_probability.keys())-set(all_variable_cases[i]))&set(eval_set))\n",
    "    non_cases_prob = [visit_probability[k] for k in non_cases]\n",
    "    if len(cases_prob) == 0 or len(non_cases_prob) == 0:\n",
    "        continue\n",
    "    if mean(cases_prob) > mean(non_cases_prob):\n",
    "        wasserstein_distance_results_eval[i]= wasserstein_distance(cases_prob, non_cases_prob)\n",
    "    else:\n",
    "        wasserstein_distance_results_eval[i]= -1*wasserstein_distance(cases_prob, non_cases_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "opening-albany",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1661/1661 [00:00<00:00, 2588.68it/s]\n"
     ]
    }
   ],
   "source": [
    "##feature name, importance, EMD_training, EMD_eval, EMD_full\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for feature in tqdm(list(all_variable_cases.keys())):\n",
    "    if list(importance.importance[importance.feature == str(feature)])[0] == 0:\n",
    "        continue\n",
    "    to_add = [feature, list(importance.importance[importance.feature == str(feature)])[0]]\n",
    "    if feature in wasserstein_distance_results_training:\n",
    "        to_add.append(wasserstein_distance_results_training[feature])\n",
    "    else:\n",
    "        to_add.append('-')\n",
    "    if feature in wasserstein_distance_results_eval:\n",
    "        to_add.append(wasserstein_distance_results_eval[feature])\n",
    "    else:\n",
    "        to_add.append('-')\n",
    "    if feature in wasserstein_distance_results:\n",
    "        to_add.append(wasserstein_distance_results[feature])\n",
    "    else:\n",
    "        to_add.append('-')\n",
    "    if to_add[-3:] == ['-', '-', '-']:\n",
    "        continue\n",
    "    table_data.append(to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "metropolitan-monkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4209260198004161"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wasserstein_distance_results[datetime_variables[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "anticipated-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = ['feature', 'importance', 'wasserstein_distance_training', 'wasserstein_distance_eval',\n",
    "                 'wasserstein_distance_all_visits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "suitable-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(table_data, columns=table_columns).sort_values('importance', ascending=False).to_csv('table_s3_all_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "noted-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(table_data, columns=table_columns).sort_values('importance', ascending=False).head(n=20).to_csv('table_2_20_feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-vatican",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
