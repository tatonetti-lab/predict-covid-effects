{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "olympic-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import _pickle as pickle\n",
    "import random\n",
    "from scipy.stats import epps_singleton_2samp, wasserstein_distance, ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import sample\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chubby-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573113"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_probability = {}\n",
    "for visit_id, prob in np.array(pd.read_csv('data/rfr_model_depth_69_trees_190_preds.csv', header=None)):\n",
    "    visit_probability[int(visit_id)] = prob\n",
    "    \n",
    "len(visit_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "likely-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tunnel first: ssh -f [uni]@mimir.dbmi.columbia.edu -L 3307:127.0.0.1:3306 -N\n",
    "\n",
    "conn = pymysql.connect(host=\"127.0.0.1\", \n",
    "                       user=\"\", #uni\n",
    "                       port = ,\n",
    "                       passwd=\"\", #sql password\n",
    "                       db = \"\" ) #database\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geographic-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7825382, 1048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenotype_visits = []\n",
    "cur.execute('''select phecode, a.visit_id, a.contact_date, b.ed_dt\n",
    "                from user_vr2430.vfinal_1_predict_covid_conditions a\n",
    "                join (select visit_id, pat_mrn_id, ed_dt from user_vr2430.vfinal_1_predict_covid_visits) b using (pat_mrn_id)\n",
    "                join clinical_merge_v5_2022q1.phecode_icd10 using (icd10)\n",
    "                where a.contact_date >= b.ed_dt and a.visit_id != b.visit_id;''')\n",
    "\n",
    "for phe, visit, ct, ed_dt in cur.fetchall():\n",
    "    if visit in visit_probability:\n",
    "        phenotype_visits.append([phe,visit, ct, ed_dt])\n",
    "\n",
    "phenotype_visits = np.array(pd.DataFrame(phenotype_visits))\n",
    "\n",
    "len(phenotype_visits), len(set(phenotype_visits[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applied-testimony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5002965"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('''select distinct a.visit_id, a.contact_date, b.ed_dt\n",
    "                from user_vr2430.vfinal_1_predict_covid_conditions a\n",
    "                join (select visit_id, pat_mrn_id, ed_dt from user_vr2430.vfinal_1_predict_covid_visits) b using (pat_mrn_id)\n",
    "                where a.contact_date >= b.ed_dt and a.visit_id != b.visit_id;''')\n",
    "\n",
    "followup_visits = []\n",
    "for visit, ct, ed_dt in cur.fetchall():\n",
    "    if visit in visit_probability:\n",
    "        followup_visits.append([visit, ct, ed_dt])\n",
    "        \n",
    "len(followup_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "first-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "followup_visits = np.array(pd.DataFrame(followup_visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vulnerable-spanking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277994, 529295)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(phenotype_visits[:,1])), len(set(followup_visits[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "political-sense",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7825382/7825382 [00:29<00:00, 268994.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(984, 1002, 1013, 1018, 1037, 1043, 1048, 1048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenotype_visits_7_all = defaultdict(list)\n",
    "phenotype_visits_14_all = defaultdict(list)\n",
    "phenotype_visits_21_all = defaultdict(list)\n",
    "phenotype_visits_28_all = defaultdict(list)\n",
    "phenotype_visits_3m_all = defaultdict(list)\n",
    "phenotype_visits_6m_all = defaultdict(list)\n",
    "phenotype_visits_9m_all = defaultdict(list)\n",
    "phenotype_visits_1y_all = defaultdict(list)\n",
    "\n",
    "for phe, visit_id, diag_date, ed_date in tqdm(phenotype_visits):\n",
    "        if visit_id not in visit_probability:\n",
    "            continue\n",
    "        if (diag_date-ed_date).days <= 7:\n",
    "            phenotype_visits_7_all[phe].append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 14:\n",
    "            phenotype_visits_14_all[phe].append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 21:\n",
    "            phenotype_visits_21_all[phe].append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 28:\n",
    "            phenotype_visits_28_all[phe].append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 91:\n",
    "            phenotype_visits_3m_all[phe].append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 183:\n",
    "            phenotype_visits_6m_all[phe].append([visit_id, diag_date, ed_date])  \n",
    "        if (diag_date-ed_date).days <= 274:\n",
    "            phenotype_visits_9m_all[phe].append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 365:\n",
    "            phenotype_visits_1y_all[phe].append([visit_id, diag_date, ed_date])\n",
    "\n",
    "            \n",
    "len(phenotype_visits_7_all), len(phenotype_visits_14_all), len(phenotype_visits_21_all), len(phenotype_visits_28_all), len(phenotype_visits_3m_all) ,len(phenotype_visits_6m_all), len(phenotype_visits_9m_all) ,len(phenotype_visits_1y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tamil-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5002965/5002965 [00:17<00:00, 281157.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(266074, 502360, 717314, 922617, 2239595, 3471263, 4184347, 4589280)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followup_visits_7 = []\n",
    "followup_visits_14 = []\n",
    "followup_visits_21 = []\n",
    "followup_visits_28 = []\n",
    "followup_visits_3m = []\n",
    "followup_visits_6m = []\n",
    "followup_visits_9m = []\n",
    "followup_visits_1y = []\n",
    "\n",
    "for visit_id, diag_date, ed_date in tqdm(followup_visits):\n",
    "        if visit_id not in visit_probability:\n",
    "            continue\n",
    "        if (diag_date-ed_date).days <= 7:\n",
    "            followup_visits_7.append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 14:\n",
    "            followup_visits_14.append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 21:\n",
    "            followup_visits_21.append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 28:\n",
    "            followup_visits_28.append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 91:\n",
    "            followup_visits_3m.append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 183:\n",
    "            followup_visits_6m.append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <= 274:\n",
    "            followup_visits_9m.append([visit_id, diag_date, ed_date])\n",
    "        if (diag_date-ed_date).days <=365:\n",
    "            followup_visits_1y.append([visit_id, diag_date, ed_date])\n",
    "\n",
    "len(followup_visits_7), len(followup_visits_14), len(followup_visits_21), len(followup_visits_28), len(followup_visits_3m) ,len(followup_visits_6m), len(followup_visits_9m) ,len(followup_visits_1y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "reliable-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "followup_visits_7 = np.array(pd.DataFrame(followup_visits_7))\n",
    "followup_visits_14 = np.array(pd.DataFrame(followup_visits_14))\n",
    "followup_visits_21 = np.array(pd.DataFrame(followup_visits_21))\n",
    "followup_visits_28 = np.array(pd.DataFrame(followup_visits_28))\n",
    "followup_visits_3m = np.array(pd.DataFrame(followup_visits_3m))\n",
    "followup_visits_6m = np.array(pd.DataFrame(followup_visits_6m))\n",
    "followup_visits_9m = np.array(pd.DataFrame(followup_visits_9m))\n",
    "followup_visits_1y = np.array(pd.DataFrame(followup_visits_1y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "moral-mileage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266074/266074 [00:00<00:00, 940303.33it/s]\n",
      "100%|██████████| 502360/502360 [00:00<00:00, 1186426.39it/s]\n",
      "100%|██████████| 717314/717314 [00:00<00:00, 1286267.74it/s]\n",
      "100%|██████████| 922617/922617 [00:00<00:00, 1200006.75it/s]\n",
      "100%|██████████| 2239595/2239595 [00:01<00:00, 1557315.07it/s]\n",
      "100%|██████████| 3471263/3471263 [00:05<00:00, 631693.57it/s] \n",
      "100%|██████████| 4184347/4184347 [00:02<00:00, 1906044.52it/s]\n",
      "100%|██████████| 4589280/4589280 [00:02<00:00, 1963396.35it/s]\n"
     ]
    }
   ],
   "source": [
    "followup_tm_7 = defaultdict(list)\n",
    "followup_tm_14 = defaultdict(list)\n",
    "followup_tm_21 = defaultdict(list)\n",
    "followup_tm_28 = defaultdict(list)\n",
    "followup_tm_3m = defaultdict(list)\n",
    "followup_tm_6m = defaultdict(list)\n",
    "followup_tm_9m = defaultdict(list)\n",
    "followup_tm_1y = defaultdict(list)\n",
    "\n",
    "for visit_id, ed, st in tqdm(followup_visits_7):\n",
    "    followup_tm_7[visit_id].append((ed-st).days)\n",
    "for visit_id, ed, st in tqdm(followup_visits_14):\n",
    "    followup_tm_14[visit_id].append((ed-st).days)\n",
    "for visit_id, ed, st in tqdm(followup_visits_21):\n",
    "    followup_tm_21[visit_id].append((ed-st).days)\n",
    "for visit_id, ed, st in tqdm(followup_visits_28):\n",
    "    followup_tm_28[visit_id].append((ed-st).days)\n",
    "for visit_id, ed, st in tqdm(followup_visits_3m):\n",
    "    followup_tm_3m[visit_id].append((ed-st).days)\n",
    "for visit_id, ed, st in tqdm(followup_visits_6m):\n",
    "    followup_tm_6m[visit_id].append((ed-st).days)\n",
    "for visit_id, ed, st in tqdm(followup_visits_9m):\n",
    "    followup_tm_9m[visit_id].append((ed-st).days)    \n",
    "for visit_id, ed, st in tqdm(followup_visits_1y):\n",
    "    followup_tm_1y[visit_id].append((ed-st).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "overhead-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(phenotype_visits_7_all, open('data/phenotype_visits_7_all.p', 'wb'))\n",
    "pickle.dump(phenotype_visits_14_all, open('data/phenotype_visits_14_all.p', 'wb'))\n",
    "pickle.dump(phenotype_visits_21_all, open('data/phenotype_visits_21_all.p', 'wb'))\n",
    "pickle.dump(phenotype_visits_28_all, open('data/phenotype_visits_28_all.p', 'wb'))\n",
    "pickle.dump(phenotype_visits_3m_all, open('data/phenotype_visits_3m_all.p', 'wb'))\n",
    "pickle.dump(phenotype_visits_6m_all, open('data/phenotype_visits_6m_all.p', 'wb'))\n",
    "pickle.dump(phenotype_visits_9m_all, open('data/phenotype_visits_9m_all.p', 'wb'))\n",
    "pickle.dump(phenotype_visits_1y_all, open('data/phenotype_visits_1y_all.p', 'wb'))\n",
    "pickle.dump(followup_visits_7, open('data/followup_visits_7.p', 'wb'))\n",
    "pickle.dump(followup_visits_14, open('data/followup_visits_14.p', 'wb'))\n",
    "pickle.dump(followup_visits_21, open('data/followup_visits_21.p', 'wb'))\n",
    "pickle.dump(followup_visits_28, open('data/followup_visits_28.p', 'wb'))\n",
    "pickle.dump(followup_visits_3m, open('data/followup_visits_3m.p', 'wb'))\n",
    "pickle.dump(followup_visits_6m, open('data/followup_visits_6m.p', 'wb'))\n",
    "pickle.dump(followup_visits_9m, open('data/followup_visits_9m.p', 'wb'))\n",
    "pickle.dump(followup_visits_1y, open('data/followup_visits_1y.p', 'wb'))\n",
    "pickle.dump(followup_tm_7, open('data/followup_tm_7.p', 'wb'))\n",
    "pickle.dump(followup_tm_14, open('data/followup_tm_14.p', 'wb'))\n",
    "pickle.dump(followup_tm_21, open('data/followup_tm_21.p', 'wb'))\n",
    "pickle.dump(followup_tm_28, open('data/followup_tm_28.p', 'wb'))\n",
    "pickle.dump(followup_tm_3m, open('data/followup_tm_3m.p', 'wb'))\n",
    "pickle.dump(followup_tm_6m, open('data/followup_tm_6m.p', 'wb'))\n",
    "pickle.dump(followup_tm_9m, open('data/followup_tm_9m.p', 'wb'))\n",
    "pickle.dump(followup_tm_1y, open('data/followup_tm_1y.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "annoying-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1047/1047 [2:45:27<00:00,  9.48s/it] \n"
     ]
    }
   ],
   "source": [
    "survival_results_1y = []\n",
    "for phe in tqdm([i for i in phenotype_visits_1y_all.keys() if i !='']):\n",
    "    case_visits_1y = []\n",
    "    for visit_id, diag_date, ed_date in phenotype_visits_1y_all[phe]:\n",
    "        if visit_id not in visit_probability:\n",
    "            continue\n",
    "        if (diag_date-ed_date).days <= 365:\n",
    "            case_visits_1y.append([visit_id, (diag_date-ed_date).days])\n",
    "            \n",
    "    case_visits_1y = np.array(pd.DataFrame(case_visits_1y))\n",
    "    non_case_visits_1y = list((set(followup_visits_1y[:,0])-set(case_visits_1y[:,0])))\n",
    "    \n",
    "    coxph_model_data = []\n",
    "\n",
    "\n",
    "    for visit_id in set(case_visits_1y[:,0]):\n",
    "        time_to_diag = min(case_visits_1y[:,1][case_visits_1y[:,0]==visit_id])\n",
    "        covid_prob = visit_probability[visit_id]\n",
    "        coxph_model_data.append([covid_prob, 1, time_to_diag])\n",
    "    \n",
    "    for visit_id in non_case_visits_1y:\n",
    "        time_to_diag = min([365] + followup_tm_1y[visit_id])\n",
    "        covid_prob = visit_probability[visit_id]\n",
    "        coxph_model_data.append([covid_prob, 0, time_to_diag])\n",
    "    \n",
    "    \n",
    "    coxph_model_data = pd.DataFrame(coxph_model_data, columns=['covid_prob', 'phenotype', 'days'])\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(coxph_model_data, 'days', 'phenotype')\n",
    "    hz = cph.summary['exp(coef)'][0]\n",
    "    lw = cph.summary['exp(coef) lower 95%'][0]\n",
    "    up = cph.summary['exp(coef) upper 95%'][0]\n",
    "    z = cph.summary['z'][0]\n",
    "    p = cph.summary['-log2(p)'][0]\n",
    "    survival_results_1y.append([phe, len(case_visits_1y), len(non_case_visits_1y), hz, lw, up, z, p])\n",
    "    \n",
    "pd.DataFrame(survival_results_1y, columns=['phe', 'case_n', 'noncase_n', 'hazards ratio', \n",
    "                                          '95% confidence interval lower','95% confidence interval upper', 'z','-log2(p)']).to_csv('data/phenotype_copy_new_1y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-heath",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
